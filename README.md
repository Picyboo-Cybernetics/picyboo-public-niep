# NIEP: Neuro-Inspired Error Propagation

**Series:** Picyboo Public Research Series  
**Organization:** Picyboo Cybernetics Inc., Research Lab (Canada)

## Overview
Solved: The Training Problem Enabling AI to Learn Continuously Without Forgetting

Standard backpropagation updates all network weights simultaneously, causing destructive interference when learning continuous task streams. NIEP implements biologically inspired refractory periods and eligibility traces that gate parameter updates temporally and spatially. The safe-commit protocol ensures gradient updates meet stability criteria before permanent application, enabling stable continual learning and more efficient, asynchronous, distributed training.

**Keywords:** Continual Learning, Refractory Gating, Eligibility Traces, Catastrophic Interference, Federated Learning, Asynchronous Training, Energy-Efficient AI, Stability-Plasticity Dilemma

## Whitepaper
- PDF: docs/halenta-neuro-inspired-error-propagation-(NIEP)-2025-10-11-v1.pdf  
- DOI: https://doi.org/10.5281/zenodo.17357249  
- Also available on arXiv (Cornell University, USA)

## Repository purpose
Public research reference for industry and collaborators. Mirrors the technical whitepaper and provides stubs for reference implementations or models.

## Status
Openly published for transparency. Implementation stubs included. Roadmaps and code will be added as they mature.

## How to cite
> Halenta, D. N. (2025). *Neuro-Inspired Error Propagation (NIEP): Refractory Period-Based Learning for Stable, Incremental AI Systems.*  
> Picyboo Cybernetics Inc.  
> DOI: https://doi.org/10.5281/zenodo.17357249

## Links
- Website: https://picyboo.com  
- GitHub: https://github.com/Picyboo-Cybernetics/picyboo-public-niep
